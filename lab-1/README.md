# MLOps Lab 1 - Bank Customer Churn Prediction

## üìã Project Overview

This project demonstrates MLOps best practices for training a machine learning model to predict bank customer churn. It includes data validation, reproducible training, artifact generation, and Docker containerization.

**Objective:** Train a classification model to predict whether a customer will exit (Exited = 0/1) while ensuring:

- ‚úÖ Reproducibility (seeds + versions + config)
- ‚úÖ Traceability (named and preserved artifacts)
- ‚úÖ Data Quality (schema tests + validation)
- ‚úÖ Industrialization (Docker execution)

---

## üìÅ Project Structure

```
lab_1/
‚îú‚îÄ‚îÄ üìÅ .pytest_cache/          # Pytest cache (auto-generated)
‚îú‚îÄ‚îÄ üìÅ artifacts/              # Generated artifacts (DO NOT EDIT MANUALLY)
‚îÇ   ‚îú‚îÄ‚îÄ üíæ model.joblib        # Trained model pipeline
‚îÇ   ‚îú‚îÄ‚îÄ üìä metrics.json        # Performance metrics (accuracy, F1)
‚îÇ   ‚îú‚îÄ‚îÄ üìà confusion_matrix.png # Confusion matrix visualization
‚îÇ   ‚îî‚îÄ‚îÄ üìù run_info.json       # Complete training record (config + versions)
‚îú‚îÄ‚îÄ üìÅ config/
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è train.yaml          # Training configuration
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ dataset.csv         # Input dataset
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ üêç train.py            # Main training script
‚îÇ   ‚îî‚îÄ‚îÄ üêç validate_data.py    # Data validation script
‚îú‚îÄ‚îÄ üìÅ tests/
‚îÇ   ‚îî‚îÄ‚îÄ üß™ test_data.py        # Data validation tests
‚îú‚îÄ‚îÄ üö´ .gitignore              # Git ignore rules
‚îú‚îÄ‚îÄ üê≥ Dockerfile              # Docker image definition
‚îú‚îÄ‚îÄ üìñ README.md               # This file
‚îî‚îÄ‚îÄ üìã requirements.txt        # Python dependencies
```

---

## üõ†Ô∏è Setup Instructions

### Prerequisites

- Python 3.11+
- Conda (recommended) or venv
- Docker (for containerized execution)

### 1. Create Environment

**Using Conda (recommended):**

```bash
conda create -n mlops-lab1 python=3.11
conda activate mlops-lab1
```

**Using venv (alternative):**

```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac: source .venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Verify Setup

```bash
python --version  # Should show Python 3.11.x
```

---

## üöÄ Usage

### Option 1: Local Execution

#### Step 1: Validate Data

```bash
# Using pytest (recommended)
python -m pytest -q

# Or direct execution
python src/validate_data.py
```

#### Step 2: Train Model

```bash
python src/train.py
```

**Expected output:**

```
OK: {'accuracy': 0.8465, 'f1': 0.6234}
Artefacts -> artifacts/
```

#### Step 3: Check Artifacts

```bash
ls -l artifacts/
cat artifacts/metrics.json
```

---

### Option 2: Docker Execution (Recommended for Production)

#### Step 1: Build Docker Image

```bash
docker build -t mlops-lab1:1.0 .
```

#### Step 2: Run Training in Container

**Linux/macOS:**

```bash
docker run --rm -v "$(pwd)/artifacts:/app/artifacts" mlops-lab1:1.0
```

**Windows PowerShell:**

```bash
docker run --rm -v "${PWD}/artifacts:/app/artifacts" mlops-lab1:1.0
```

**Windows CMD:**

```bash
docker run --rm -v "%cd%/artifacts:/app/artifacts" mlops-lab1:1.0
```

#### Step 3: Verify Artifacts Persisted

```bash
ls artifacts/
# Should contain: model.joblib, metrics.json, confusion_matrix.png, run_info.json
```

---

## üìä Understanding the Artifacts

### 1. `model.joblib` (Binary File)

- **What:** Complete trained ML pipeline (preprocessing + model)
- **Size:** ~100-500 KB
- **Use:** Load this file to make predictions on new data

### 2. `metrics.json`

```json
{
  "accuracy": 0.8465,
  "f1": 0.6234
}
```

- **accuracy:** Overall correctness (85% of predictions correct)
- **f1:** Balance between precision and recall (better for imbalanced data)

### 3. `confusion_matrix.png`

- Visual representation of model predictions vs actual values
- Shows True Positives, True Negatives, False Positives, False Negatives

### 4. `run_info.json`

- **Most important for MLOps!**
- Contains:
  - Timestamp of training
  - Complete configuration used
  - Library versions (Python, scikit-learn, pandas, numpy)
  - Detailed classification report
- **Purpose:** Ensures complete traceability and reproducibility

---

## üîÑ Workflow Summary

```
1. Data Validation (validate_data.py)
          ‚Üì
2. Load Config (train.yaml)
          ‚Üì
3. Load & Clean Data
          ‚Üì
4. Train/Test Split (reproducible)
          ‚Üì
5. Preprocessing Pipeline (numeric + categorical)
          ‚Üì
6. Model Training (Logistic Regression)
          ‚Üì
7. Evaluation (accuracy, F1, confusion matrix)
          ‚Üì
8. Save Artifacts (model, metrics, visualization, run info)
```

---

## üìö Key MLOps Concepts Demonstrated

1. **Reproducibility:**

   - Fixed random seeds
   - Version locking (requirements.txt)
   - Configuration files

2. **Traceability:**

   - Artifact generation
   - Version tracking (run_info.json)
   - Timestamped runs

3. **Data Quality:**

   - Schema validation
   - Value range checks
   - Automated tests

4. **Containerization:**
   - Docker for environment isolation
   - Volume persistence
   - Portable execution

---

## üìù License

This is an educational project for MLOps learning.

---

## üë§ Author

Created as part of MLOps Lab 1 - DevOps & MLOps Course

---

**Last Updated:** January 2026
